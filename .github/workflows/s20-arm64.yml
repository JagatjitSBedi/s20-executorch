name: S20 DeepSeek ARM64 .pte
on:
  workflow_dispatch:
    inputs:
      model:
        description: 'DeepSeek HF ID'
        required: true
        default: 'deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct'
jobs:
  arm64:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: '3.12'
    - uses: uraimo/run-on-arch-action@v2
      with:
        arch: aarch64
        distro: ubuntu24.04
        run: |
          pip install --upgrade pip
          pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
          pip install executorch[export] transformers accelerate bitsandbytes
          python -c "
import torch, sys
from transformers import AutoTokenizer, AutoModelForCausalLM
from executorch.exir_server import ExirServer
model_id = '${{ github.event.inputs.model }}'
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map='cpu', trust_remote_code=True)
inputs = tokenizer('Hello', return_tensors='pt')
exir = ExirServer()
edge = exir.export_edge(model, inputs)
edge._save(f's20_{model_id.split('/')[-1]}.pte')
print('âœ… .pte exported')
          "
    - uses: actions/upload-artifact@v4
      with:
        name: s20-deepseek.pte
        path: s20_*.pte
